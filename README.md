# Discord AI Bot with Algion API (Gemini 3 Pro Preview)

ğŸ¤– Discord bot yang menggunakan Gemini 3 Pro Preview melalui Algion API (Free OpenAI-compatible API) untuk memberikan respons AI yang cerdas.

## Features

- âœ… `/ask` - Tanya pertanyaan ke AI (Gemini 3 Pro Preview)
- âœ… `/clear` - Hapus riwayat percakapan
- âœ… Streaming response real-time
- âœ… DM support
- âœ… Conversation history per channel
- âœ… 100% GRATIS - Algion API free forever!

## Tech Stack

- **Discord.js** v14 - Discord bot framework
- **Algion API** - Free OpenAI-compatible API
- **Gemini 3 Pro Preview** - Google's latest AI model
- **Node.js** - Runtime environment

## Setup

### 1. Clone Repository

```bash
git clone https://github.com/lutfi238/bot-discord-ai.git
cd bot-discord-ai
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Configure Environment Variables

Copy `.env.example` to `.env` dan isi dengan credentials Anda:

```bash
cp .env.example .env
```

Edit `.env`:

```env
# Discord Bot
BOT_TOKEN=your_discord_bot_token_here
CLIENT_ID=your_discord_client_id_here

# Algion API
ALGION_API_KEY=free
ALGION_MODEL=gemini-3-pro-preview
ALGION_BASE_URL=https://api.algion.dev/v1
```

**Cara mendapatkan credentials:**

- **Discord Bot Token**: https://discord.com/developers/applications
- **Algion API Key**: https://t.me/AlgionBot (Telegram bot - FREE!)
  - Atau gunakan `free` sebagai API key (default)

### 4. Deploy Commands

```bash
npm run deploy
```

### 5. Run Bot Locally

```bash
npm start
```

```

## Deployment (FREE Hosting)

**Cara mendapatkan credentials:**

- **Discord Bot Token**: https://discord.com/developers/applications### Option 1: Replit (Recommended - FREE 24/7)

- **Groq API Key**: https://console.groq.com/keys (FREE!)1. Import repository di https://replit.com

2. Set Secrets (environment variables)

### 4. Deploy Commands3. Run bot

```bash4. Setup UptimeRobot untuk keep-alive

node deploy-commands.js

```ğŸ“– [Panduan lengkap Replit](REPLIT_DEPLOYMENT.md)



### 5. Start Bot### Option 2: Render.com (FREE)

```bash1. Connect GitHub di https://render.com

npm start2. Set environment variables

```3. Deploy!



## ğŸ’¬ UsageğŸ“– [Panduan lengkap Render](RENDER_DEPLOYMENT.md)



### `/ask [question] [stream]`### Option 3: Fly.io (FREE with credit card)

Bertanya ke AI dengan LLaMA 3.3 70B model.ğŸ“– [Panduan lengkap Fly.io](FLY_DEPLOYMENT.md)



**Options:**## Commands

- `question` (required): Pertanyaan Anda

- `stream` (optional): Enable/disable streaming (default: true)### `/ask <question>`

Tanya pertanyaan ke AI.

**Contoh:**

```**Options:**

/ask question: Jelaskan cara kerja neural network- `dm: true` - Kirim reply via DM

/ask question: Buatkan kode Python untuk sorting stream: false- `stream: true/false` - Enable/disable streaming response

```

**Example:**

### `/clear````

Mulai percakapan baru dan lihat statistik:/ask question: Jelaskan apa itu React

- Memory usage```

- Active conversations

- Groq API rate limit usage (requests & tokens)### `/clear`

Hapus riwayat percakapan di channel saat ini.

## âš ï¸ Rate Limit Handling

## Project Structure

Bot akan otomatis mendeteksi dan menampilkan pesan rate limit:```

bot-discord-ai/

```â”œâ”€â”€ commands/          # Slash commands

â±ï¸ Groq API Rate Limit Reachedâ”‚   â”œâ”€â”€ ask.js        # /ask command

â”‚   â””â”€â”€ clear.js      # /clear command

â±ï¸ Rate Limit: Requests Per Minuteâ”œâ”€â”€ utils/            # Utility functions

Reached limit of 30 requests/minute. Current: 30/30â”‚   â”œâ”€â”€ api.js        # API call handlers

â”‚   â”œâ”€â”€ embeds.js     # Discord embeds

â° Please try again in: 45 secondsâ”‚   â”œâ”€â”€ formatting.js # Message formatting

```â”‚   â””â”€â”€ prompt.js     # System prompt

â”œâ”€â”€ index.js          # Main bot file

Rate limiter melacak:â”œâ”€â”€ deploy-commands.js # Command deployment

- âœ… Requests per minute (30)â”œâ”€â”€ .env.example      # Environment template

- âœ… Requests per day (1000)â””â”€â”€ package.json      # Dependencies

- âœ… Tokens per minute (12K)```

- âœ… Tokens per day (100K)

## Environment Variables

## ğŸ¯ Rate Limit Stats

| Variable | Description | Example |

Gunakan `/clear` untuk melihat usage saat ini:|----------|-------------|---------|

| `BOT_TOKEN` | Discord bot token | `MTI4Nzc3...` |

```| `CLIENT_ID` | Discord application client ID | `1287772818964221952` |

ğŸ“Š Groq API Usage (Requests)| `OPENROUTER_API_KEY` | Comet API key | `sk-...` |

Minute: 15/30 (50%)| `OPENROUTER_MODEL` | AI model to use | `claude-sonnet-4-5` |

Day: 234/1000 (23%)| `OPENROUTER_BASE_URL` | API base URL | `https://api.cometapi.com/v1` |



ğŸ¯ Groq API Usage (Tokens)## Free Tier Limits

Minute: 5,432/12,000 (45%)

Day: 45,678/100,000 (46%)### Comet API

```- Check pricing: https://cometapi.com/pricing



## ğŸ’¾ Memory Optimization### Replit

- Free tier dengan UptimeRobot = 24/7 uptime

Bot dioptimalkan untuk hosting dengan RAM 500MB:- 1GB RAM, 1 vCPU



- Heap limit: 350MB### Render.com

- Auto garbage collection- 750 jam/bulan (cukup untuk 24/7)

- Conversation cleanup (30 min expiry)- Bot sleep setelah 15 menit idle

- Max 50 conversations

- Max 6 messages per conversation## Contributing

Pull requests are welcome! Untuk perubahan besar, mohon buka issue terlebih dahulu.

Lihat `MEMORY_OPTIMIZATION.md` untuk detail lengkap.

## License

## ğŸŒ DeploymentISC



### Wispbyte## Support

```bashJika ada pertanyaan atau issue, silakan buka [GitHub Issues](https://github.com/lutfi238/bot-discord-ai/issues)

bash start.sh

```---



### ReplitMade with â¤ï¸ using Claude Sonnet 4.5
```bash
npm run replit
```

### Docker
```bash
docker build -t discord-bot .
docker run --memory=500m -e GROQ_API_KEY=xxx discord-bot
```

### Fly.io
```bash
fly deploy
```

## ğŸ“ Project Structure

```
bot-discord-ai/
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ ask.js           # Main AI command with rate limiting
â”‚   â””â”€â”€ clear.js         # Clear conversation & show stats
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ api.js           # Groq API integration
â”‚   â”œâ”€â”€ groqRateLimit.js # Rate limit manager
â”‚   â”œâ”€â”€ memoryMonitor.js # Memory usage tracking
â”‚   â”œâ”€â”€ formatting.js    # Message formatting
â”‚   â”œâ”€â”€ prompt.js        # System prompts
â”‚   â””â”€â”€ embeds.js        # Discord embeds
â”œâ”€â”€ index.js             # Main bot file
â”œâ”€â”€ deploy-commands.js   # Command deployment
â”œâ”€â”€ package.json         # Dependencies
â”œâ”€â”€ .env.example         # Environment template
â”œâ”€â”€ README.md            # This file
â”œâ”€â”€ MEMORY_OPTIMIZATION.md
â””â”€â”€ DEPLOYMENT.md
```

## ğŸ” Monitoring

### Memory Usage
Bot logs memory setiap 15 menit:
```
ğŸ“Š Bot Ready: Heap 45/89MB | RSS 125MB
ğŸ“Š Periodic Check: Heap 52/89MB | RSS 145MB
```

### Rate Limits
Bot tracks rate limits secara real-time dan menampilkan warning:
```
âš ï¸ HIGH MEMORY WARNING: 455MB RSS
ğŸ§¹ Emergency cleanup: removed 25 conversations
```

## ğŸ†˜ Troubleshooting

### Rate Limit Error
```
Error: Rate limit exceeded
```
**Solusi:** Tunggu sesuai waktu yang ditampilkan bot. Rate limit akan reset otomatis.

### Out of Memory
```
JavaScript heap out of memory
```
**Solusi:** 
1. Gunakan `/clear` di semua channel
2. Restart bot
3. Kurangi `MAX_CONVERSATIONS` di `index.js`

### Bot Not Responding
1. Cek log untuk error
2. Verify Groq API key valid
3. Pastikan rate limit tidak exceeded
4. Restart bot

## ğŸ“š Documentation

- [Memory Optimization Guide](MEMORY_OPTIMIZATION.md)
- [Deployment Guide](DEPLOYMENT.md)
- [Groq API Docs](https://console.groq.com/docs)
- [Discord.js Guide](https://discordjs.guide/)

## âš¡ Why Groq?

- **Ultra-fast**: 10x faster than traditional APIs
- **Free tier**: Generous limits for small projects
- **LLaMA 3.3 70B**: State-of-the-art open model
- **Low latency**: Perfect for real-time chat
- **OpenAI compatible**: Easy migration

## ğŸ”— Links

- **Repository**: https://github.com/lutfi238/bot-discord-ai
- **Groq Console**: https://console.groq.com
- **Discord Developer Portal**: https://discord.com/developers/applications

## ğŸ“ License

ISC

## ğŸ‘¤ Author

lutfi238

## ğŸ™ Credits

- Groq for ultra-fast LLM inference
- Meta for LLaMA 3.3 model
- Discord.js community

---

**Made with â¤ï¸ and optimized for 500MB RAM hosting**
